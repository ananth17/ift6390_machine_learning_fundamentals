{
 "metadata": {
  "name": "",
  "signature": "sha256:42432db391143f5bd05920f7f0e5706062f9acebdb190afb1aa404911abff342"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification lin\u00e9aire"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vous aurez \u00e0 implanter un mod\u00e8le de classification lin\u00e9aire particulier: le perceptron. Il s'agit de la formulation classique (classification binaire) et on vous demande d'utiliser la proc\u00e9dure d'entrainement en-ligne, c'est \u00e0 dire la descente de gradient stochastique.\n",
      "\n",
      "Les algorithmes que nous impl\u00e9menterons dor\u00e9navant suivront l'architecture de la classe d\u00e9finit dans la cellule suivante, avec obligatoirement les m\u00e9thodes `train` et `compute_predictions`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "%pylab inline\n",
      "%aimport numpy\n",
      "np=numpy\n",
      "import utilitaires5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Algorithme:\n",
      "    def __init__(self, parametres):\n",
      "        \"\"\"\n",
      "        Constructeur de la classe.\n",
      "        \n",
      "        Prend les param\u00e8tres donn\u00e9es \u00e0 la constuction de la classe et initialise ses attribues.\n",
      "        \"\"\"\n",
      "            \n",
      "    def train(self, train_data, autres_parametres):\n",
      "        \"\"\"\n",
      "        Entraine le mod\u00e8le d'apprentissage\n",
      "        \n",
      "        Prend en entr\u00e9e une matrice de donn\u00e9es et entra\u00eene le mod\u00e8le. D'autre param\u00e8tres peuvent \u00eatre d\u00e9fini ici \n",
      "        tel que le nombre d'\u00e9poque d'entra\u00eenement par exemple.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        train_data : array\n",
      "            matrice de dimension (n,d) o\u00f9 n est le nombre d'exemples et d le nombre de dimensions\n",
      "        \"\"\"\n",
      "        \n",
      "    def compute_predictions(self, test_data):\n",
      "        \"\"\"\n",
      "        Calcule les pr\u00e9dictions du mod\u00e8le\n",
      "        \n",
      "        Calcule les pr\u00e9dictions \u00e0 partir d'une matrice de test. Donne en sortie une pr\u00e9diction \n",
      "        pour chaque classe dans le cas d'une classification multiclasse. L'argmax ou le signe \n",
      "        ne sont pas calcul\u00e9s dans cette m\u00e9thode.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        test_data : array\n",
      "            matrice de dimension (n,d) o\u00f9 n est le nombre d'exemples et d le nombre de dimensions\n",
      "            \n",
      "        Returns\n",
      "        -------\n",
      "        array\n",
      "            matrice de dimension (n,c) o\u00f9 n est le nombre d'exemples et c le nombre de classe\n",
      "        \"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "L'\u00e9quation de base du perceptron comme vu dans les note de cours est la suivante. On notera ici la version $w$ incluant le biais, donc $w = (b, w_1, w_2, \\dots, w_d)$ et $X_i = (1, X_{i,1}, X_{i,2}, \\dots, X_{i,d})$\n",
      "\n",
      "$$\\hat{y_i} = h\\left(\\sum_{j=0}^d w_j X_{i,j}\\right)$$ \n",
      "\n",
      "o\u00f9 $h$ est une fonction non-lin\u00e9aire. Dans ce cas ci, on va se contenter de prendre le signe de la sortie du neurone avec la fonction `np.sign` qui renvoit -1 si c'est n\u00e9gatif ou 1 si c'est nulle ou positif. Impl\u00e9mentez donc seulement l'\u00e9quation suivante \u00e0 l'int\u00e9rieur de la classe `Perceptron`. Le code de la derni\u00e8re cellule se charge d'appeler `np.sign` sur les sorties de `compute_predictions`.\n",
      "\n",
      "$$\\hat{y_i} = \\sum_{j=0}^d w_j X_{i,j}$$ \n",
      "\n",
      "La mise \u00e0 jour des gradients se calcule avec le gradient de la fonction de co\u00fbt $L$ par rapport \u00e0 $w$ comme toujours.\n",
      "\n",
      "$$L = \\sum_{i=1}^n I_{\\{y_i=\\hat{y_i}\\}}$$\n",
      "\n",
      "O\u00f9 $I$ est une fonction indicatrice qui est \u00e9gale \u00e0 1 si l'\u00e9nonc\u00e9 est vrai et 0 sinon. On parle ici bien s\u00fbr de $y_i$ et $\\hat{y_i}$ $\\in \\{-1, 1\\}$. Cela fait une diff\u00e9rence pour le calcul du gradient, mais vous n'avez pas besoin de `np.sign` pour l'impl\u00e9mentation. Rappelez vous au moment de la comparaison que la multiplication de deux valeurs de m\u00eame signe r\u00e9sulte en un nombre plus grand ou \u00e9gale \u00e0 0. ;-)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Perceptron:\n",
      "\n",
      "    def __init__(self, mu):\n",
      "        \"\"\"\n",
      "        Constructeur de la classe.\n",
      "        \n",
      "        Prend les param\u00e8tres donn\u00e9es \u00e0 la constuction de la classe et initialise ses attribues.\n",
      "        \"\"\"\n",
      "        # mu est le taux d'apprentissage.\n",
      "        self.mu = mu\n",
      "    \n",
      "    def train(self, train_data, max_epoque=float('inf')):\n",
      "        \"\"\"\n",
      "        Entraine le mod\u00e8le d'apprentissage\n",
      "        \n",
      "        Prend en entr\u00e9e une matrice de donn\u00e9es et entra\u00eene le mod\u00e8le. D'autre param\u00e8tres peuvent \u00eatre d\u00e9fini ici \n",
      "        tel que le nombre d'\u00e9poque d'entra\u00eenement par exemple.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        train_data : array\n",
      "            matrice de dimension (n,d) o\u00f9 n est le nombre d'exemples et d le nombre de dimensions\n",
      "        \"\"\"\n",
      "        # Cette fonction doit d\u00e9terminer les valeurs des parametres.\n",
      "        #   train_data: chaque ligne contient un exemple (traits et \u00e9tiquette).\n",
      "        \n",
      "        # 1) Initialisation des param\u00e8tres. \n",
      "        # Initialisez les poids \u00e0\u00a0de petites valeurs et le biais \u00e0 0.\n",
      "        self.weights = ?\n",
      "        \n",
      "        # 2) Entrainement\n",
      "        # Tant que votre mod\u00e8le n'obtient pas la s\u00e9paration lin\u00e9aire \n",
      "        # des donn\u00e9es continuer la proc\u00e9dure d'entrainement en-ligne.\n",
      "        # C'est sans danger ici, car la d\u00e9mo sp\u00e9cifie des classes qui\n",
      "        # sont lin\u00e9airement s\u00e9parables \u00e9tant donn\u00e9s les attributs.\n",
      "        #     - Si erreur -> mise \u00e0 jour des param\u00e8tres.\n",
      "        i = 0\n",
      "        count = 0 # on arr\u00eate quand l'ensemble est lin\u00e9airement s\u00e9par\u00e9\n",
      "        epoque = 0\n",
      "        while count < train_data.shape[0] and epoque < max_epoque:\n",
      "            # impl\u00e9mentez le test d'erreur de classification\n",
      "            # et impl\u00e9mentez la mise \u00e0 jour des poids\n",
      "            # sans oublier d'incr\u00e9menter les compteurs count et \u00e9poque\n",
      "            # afin que l'entra\u00eenement termine un jour!\n",
      "\n",
      "    def compute_predictions(self, test_data):\n",
      "        \"\"\"\n",
      "        Calcule les pr\u00e9dictions du mod\u00e8le\n",
      "        \n",
      "        Calcule les pr\u00e9dictions \u00e0 partir d'une matrice de test. Donne en sortie une pr\u00e9dictions \n",
      "        pour chaque classe dans le cas d'une classification multiclasse. L'argmax n'est pas calcul\u00e9 dans cette m\u00e9thode.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        test_data : array\n",
      "            matrice de dimension (n,d) o\u00f9 n est le nombre d'exemples et d le nombre de dimensions\n",
      "            \n",
      "        Returns\n",
      "        -------\n",
      "        array\n",
      "            matrice de dimension (n,c) o\u00f9 n est le nombre d'exemples et c le nombre de classe\n",
      "        \"\"\"\n",
      "        \n",
      "        # A COMPL\u00c9TER!\n",
      "        # Cette fonction doit utiliser les param\u00e8tres appris pour calculer\n",
      "        # la valeur de sortie pour les exemples de test_data (un exemple\n",
      "        # par ligne, seulement les traits).\n",
      "  \n",
      "        # 1) Vous devez calculer la vraie valeur de sorties.\n",
      "        sorties = []\n",
      "        for i in xrange(len(test_data)):\n",
      "        \n",
      "            # ...\n",
      "        \n",
      "        return sorties"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# On commence par charger iris\n",
      "iris = np.loadtxt('iris.txt')\n",
      "data = iris\n",
      "\n",
      "# On se limite au cas de la classification BINAIRE donc on va seulement garder \n",
      "# donn\u00e9es des 2 premi\u00e8res classes.\n",
      "# Ici on garde juste les exemples avec l'etiquette 1 et 2.\n",
      "data = data[data[:,-1]<3,:]\n",
      "# Ici on transforme chaque etiquette qui est egale a 2 en -1, pour avoir les \n",
      "# m\u00eames \u00e9tiquettes que dans la formulation standard du perceptron (1 et -1).\n",
      "data[data[:,-1]==2,-1] = -1\n",
      "\n",
      "# On se limite \u00e0 des donn\u00e9es dont la dimension est 2, de fa\u00e7on \u00e0 pouvoir visualiser\n",
      "# la fronti\u00e8re de decision avec la fonction gridplot.\n",
      "train_cols = [2,3]\n",
      "# Une variable pour contenir l'indice de la colonne correspondant aux \u00e9tiquettes.\n",
      "target_ind = [data.shape[1] - 1]\n",
      "\n",
      "# Nombre de classes\n",
      "n_classes = 2\n",
      "# Nombre de points d'entrainement\n",
      "n_train = 75\n",
      "# Taille de la grille = grid_size x grid_size\n",
      "grid_size = 50\n",
      "\n",
      "print \"On va entrainer un perceptron sur \", n_train, \" exemples d'entrainement\"\n",
      "\n",
      "# decommenter pour avoir des resultats non-deterministes \n",
      "random.seed(3395)\n",
      "\n",
      "# D\u00e9terminer au hasard des indices pour les exemples d'entrainement et de test\n",
      "inds = range(data.shape[0])\n",
      "random.shuffle(inds)\n",
      "train_inds = inds[:n_train]\n",
      "test_inds = inds[n_train:]\n",
      "    \n",
      "# Separer les donnees dans les deux ensembles: entrainement et test.\n",
      "train_set = data[train_inds,:]\t# garder les bonnes lignes\n",
      "train_set = train_set[:,train_cols + target_ind]  # garder les bonnes colonnes\n",
      "test_set = data[test_inds,:]\n",
      "test_set = test_set[:,train_cols + target_ind]\n",
      "\n",
      "# Separarer l'ensemble de test: entrees et etiquettes.\n",
      "test_inputs = test_set[:,:-1]\n",
      "test_labels = test_set[:,-1]\n",
      "\n",
      "# Le taux d'apprentissage\n",
      "mu = 0.1\n",
      "\n",
      "# Cr\u00e9er et entrainer le modele\n",
      "model_perceptron = Perceptron(mu)\n",
      "model_perceptron.train(train_set)\n",
      "\n",
      "# Obtenir les sorties sur l'ensemble de test.\n",
      "t1 = time.clock()\n",
      "les_sorties = model_perceptron.compute_predictions(test_inputs)\n",
      "t2 = time.clock()\n",
      "print 'Ca nous a pris ', t2-t1, ' secondes pour calculer les predictions sur ', test_inputs.shape[0],' points de test'\n",
      "\n",
      "# Convertir les sorties en classe. On prend le signe.\n",
      "classes_pred = numpy.sign(les_sorties)\n",
      "   \n",
      "# Mesurer la performance.\n",
      "err = 1.0 - numpy.mean(test_labels==classes_pred)\n",
      "print \"L'erreur de test est de \", 100.0 * err,\"%\"\n",
      "\n",
      "# Affichage graphique\n",
      "if len(train_cols) == 2:\n",
      "    # Surface de decision\n",
      "    t1 = time.clock()\n",
      "    utilitaires5.gridplot(model_perceptron,train_set,test_set,n_points = grid_size)\n",
      "    t2 = time.clock()\n",
      "    print 'Ca nous a pris ', t2-t1, ' secondes pour calculer les predictions sur ', grid_size * grid_size, ' points de la grille'\n",
      "    filename = 'grille_' + '_c1=' + str(train_cols[0]) + '_c2=' + str(train_cols[1])+'.png'\n",
      "    print 'On va sauvegarder la figure dans ', filename\n",
      "    pylab.savefig(filename,format='png')\n",
      "        \n",
      "else:\n",
      "    print 'Trop de dimensions (', len(train_cols),') pour pouvoir afficher la surface de decision'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'np' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-8056dfcf853b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# On commence par charger iris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iris.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# On se limite au cas de la classification BINAIRE donc on va seulement garder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}